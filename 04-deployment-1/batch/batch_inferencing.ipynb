{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch deployment\n",
    "\n",
    "Goals:\n",
    "This is an example of turning a training notebook to a batch inferencing notebook.\n",
    "\n",
    "* Turn te notebook for training a model into a notebook for applyin the model \n",
    "* Turn the notebook into a script\n",
    "* Clean it and parameterize it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import pickle\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterizing the input and output data \n",
    "year = 2021\n",
    "month = 3\n",
    "\n",
    "input_file = f'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "output_file = f'output/green_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "\n",
    "# other parameters\n",
    "RUN_ID = os.getenv('RUN_ID', '74de625dfdf14d32a8a939330f51c35a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "# function to generate uuid\n",
    "def generate_uuids(n):\n",
    "    ride_ids = []\n",
    "    for i in range(n):\n",
    "        ride_ids.append(str(uuid.uuid4()))\n",
    "    return ride_ids\n",
    "    \n",
    "\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    # assigning unique ids to the rows in the df\n",
    "    df['ride_id'] = generate_uuids(len(df))\n",
    "\n",
    "    return df\n",
    "\n",
    "def prepare_dictionaries(df: pd.DataFrame):\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functionize the model application steps\n",
    "\n",
    "def load_model(run_id):\n",
    "    logged_model = f'02-exp-tracking/mlruns/1/{RUN_ID}/artifacts/models_mlflow/model.xgb'  # the 1 is for the experiment id\n",
    "    model = mlflow.pyfunc.load_model(logged_model)\n",
    "    return model \n",
    "\n",
    "\n",
    "def apply_model(input_file, run_id, model_version, output_file):\n",
    "    df = read_dataframe(input_file) # getting the data\n",
    "    dicts = prepare_dictionaries(df)\n",
    "\n",
    "    model = load_model(run_id)\n",
    "    y_pred = model.predict(dicts)\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['ride_id'] = df['ride_id']\n",
    "    df_result['lpep_pickup_datetime'] = df['lpep_pickup_datetime']\n",
    "    df_result['PULocationID'] = df['PULocationID']\n",
    "    df_result['DOLocationID'] = df['DOLocationID']\n",
    "    df_result['actual_duration'] = df['duration']\n",
    "    df_result['predicted_duration'] = y_pred\n",
    "    df_result['diff'] = df_result['actual_duration'] - df_result['predicted_duration']\n",
    "    df_result['model_version'] = RUN_ID\n",
    "    # save new data \n",
    "    df_result.to_parquet(output_file, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output dir\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model\n",
    "apply_model(input_file= input_file,\n",
    "            run_id= RUN_ID,\n",
    "            output_file=output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the notebook to python script\n",
    "* Run the command in terminal `jupyter nbconvert --to script batch_inferencing.ipynb` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
